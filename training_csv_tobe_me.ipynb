{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yE8J3MxUg0Tm"
      },
      "source": [
        "# Training the Gemini Model with your text\n",
        "\n",
        "First configure the Colab can access your drive folder where you put hte CSV file with your text;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8dhbUGKaf6V",
        "outputId": "aa0fbb66-bff4-448e-e406-b22c1b5f55ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJimLN3YhOTP"
      },
      "source": [
        "Read the csv file and transform in the pandas data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4jp6Z5TQaf6W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "msgs = pd.read_csv('/content/drive/MyDrive/COLAB/msg.csv',delimiter=\"|\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkSNNDCphXXz"
      },
      "source": [
        "Install the Keras, Tensorflow and keras-nlp to easely ge the Gemini Model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpqTjEV2bNl_",
        "outputId": "da70c6f8-22ae-4078-e650-e7fd7d3f7f7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.1.1 0.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U keras-nlp\n",
        "!pip install -q -U tensorflow==2.16.1\n",
        "!pip install -q -U keras>=3\n",
        "\n",
        "import keras\n",
        "import keras_nlp\n",
        "print(keras.__version__ , keras_nlp.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj68Twkthil1"
      },
      "source": [
        "Set up the **KAGGLE_KEY** and **KAGGLE_USERNAME** to download the model .\n",
        "\n",
        "You can do the process hard, download the model file and configure the tensorflow/keras to fit with your text. But has a easy way and I use it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QjT9o_gZgmtu"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"KAGGLE_KEY\"]= userdata.get('KAGGLE_KEY')\n",
        "os.environ[\"KAGGLE_USERNAME\"]= userdata.get('KAGGLE_USERNAME')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVyPQIwxiqzL"
      },
      "source": [
        "Finally ...\n",
        "\n",
        "Get the Gemini model and fine turn with your text. after teste the model again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "D22i04Xcaf6W",
        "outputId": "849ac6e0-2e0f-412f-fd9a-327eaf9094f1"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "import keras\n",
        "import keras_nlp\n",
        "\n",
        "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\n",
        "print(gemma_lm.generate(\"você vê uma pessoa sempre agitada?\", max_length=256))\n",
        "gemma_lm.backbone.enable_lora(rank=64)\n",
        "gemma_lm.fit(msgs, epochs=3, batch_size=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GytsIrgiuQv"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(gemma_lm.generate(\"você vê uma pessoa sempre agitada?\", max_length=256))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
