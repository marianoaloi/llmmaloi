{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Gemini Model with your text\n",
        "\n",
        "First configure the Colab can access your drive folder where you put hte CSV file with your text;"
      ],
      "metadata": {
        "id": "yE8J3MxUg0Tm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8dhbUGKaf6V",
        "outputId": "aa0fbb66-bff4-448e-e406-b22c1b5f55ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the csv file and transform in the pandas data frame."
      ],
      "metadata": {
        "id": "LJimLN3YhOTP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4jp6Z5TQaf6W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "msgs = pd.read_csv('/content/drive/MyDrive/COLAB/msg.csv',delimiter=\"|\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the Keras, Tensorflow and keras-nlp to easely ge the Gemini Model."
      ],
      "metadata": {
        "id": "kkSNNDCphXXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U keras-nlp\n",
        "!pip install -q -U tensorflow==2.16.1\n",
        "!pip install -q -U keras>=3\n",
        "\n",
        "print(keras.__version__ , keras_nlp.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpqTjEV2bNl_",
        "outputId": "da70c6f8-22ae-4078-e650-e7fd7d3f7f7a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.1.1 0.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up the **KAGGLE_KEY** and **KAGGLE_USERNAME** to download the model .\n",
        "\n",
        "You can do the process hard, download the model file and configure the tensorflow/keras to fit with your text. But has a easy way and I use it."
      ],
      "metadata": {
        "id": "Vj68Twkthil1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"KAGGLE_KEY\"]= userdata.get('KAGGLE_KEY')\n",
        "os.environ[\"KAGGLE_USERNAME\"]= userdata.get('KAGGLE_USERNAME')"
      ],
      "metadata": {
        "id": "QjT9o_gZgmtu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally ...\n",
        "\n",
        "Get the Gemini model and fine turn with your text. after save the model."
      ],
      "metadata": {
        "id": "LVyPQIwxiqzL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "D22i04Xcaf6W",
        "outputId": "849ac6e0-2e0f-412f-fd9a-327eaf9094f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7e8586d4ee60>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 97, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras_nlp'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_nlp'"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "import keras\n",
        "import keras_nlp\n",
        "\n",
        "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\n",
        "gemma_lm.backbone.enable_lora(rank=64)\n",
        "gemma_lm.fit(msgs, epochs=3, batch_size=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1GytsIrgiuQv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}